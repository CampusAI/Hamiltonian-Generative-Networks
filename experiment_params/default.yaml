# Experiment ID
experiment_id: "pendulum_test"
model_save_dir: "saved_models"

gpu_id: 0  # Will use this gpu if available

# Define environment
environment:
  name: "Pendulum"
  mass: 0.5
  length: 1
  g: 3

# Define data characteristics NOTE: Maybe this should be joined with environment params
dataset:
  img_size: 32
  noise_std: 0
  radius_bound: [1.3, 2.3]
  world_size: 1.5

# Define rollout
rollout:
  seq_length: 30
  delta_time: 0.1
  n_channels: 3

# Define networks architectures
networks:
  encoder:
    hidden_conv_layers: 6
    n_filters: [32, 64, 64, 64, 64, 64, 64]
    kernel_sizes: [3, 3, 3, 3, 3, 3, 3, 3]
    strides: [1, 1, 1, 1, 1, 1, 1, 1]
    out_channels: 48
  transformer:
    hidden_conv_layers: 2
    n_filters: [64, 64, 64]
    kernel_sizes: [3, 3, 3, 3]
    strides: [2, 2, 2, 1]
    out_channels: 16  # Channels of q, and p splitted
  hamiltonian:
    hidden_conv_layers: 6
    in_shape: [16, 4, 4]  # Should be coherent with transformer output
    n_filters: [32, 64, 64, 64, 64, 64, 64, 64]
    kernel_sizes: [3, 3, 3, 3, 3, 3, 3, 3]
    strides: [1, 1, 1, 1, 1, 1, 1, 1]
  decoder:
    n_residual_blocks: 3
    n_filters: [64, 64, 64]
    kernel_sizes: [3, 3, 3, 3]

# Define HGN Integrator
integrator:
  method: "Euler"

# Define optimization
optimization:
  epochs: 100
  batch_size: 1
  # Learning rates
  encoder_lr: 1.5e-4
  transformer_lr: 1.5e-4
  hnn_lr: 1.5e-4
  decoder_lr: 1.5e-4